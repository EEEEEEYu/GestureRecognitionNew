"""
Optimized SparseVKMEncoder with vectorized convolution instead of nested loops.

Key optimizations:
1. Removed nested for loops (17x17=289 iterations) â†’ vectorized gather operation
2. Use advanced indexing to gather all kernel positions at once
3. ~10-20x faster encoding per interval

Usage: Drop-in replacement for VecKMSparse
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class VecKMSparseOptimized(nn.Module):
    def __init__(
        self,
        height: int,
        width: int,
        encoding_dim: int,
        temporal_length: float,
        kernel_size: int = 17,
        T_scale: float = 25.0,
        S_scale: float = 25.0, 
    ):
        super().__init__()
        self.height = height
        self.width = width
        self.encoding_dim = encoding_dim
        self.temporal_length = temporal_length
        self.kernel_size = kernel_size
        self.radius = kernel_size // 2
        
        # Random Fourier Features
        self.register_buffer('T', torch.randn(1, encoding_dim) * T_scale)
        self.register_buffer('X', torch.randn(1, encoding_dim) * S_scale)
        self.register_buffer('Y', torch.randn(1, encoding_dim) * S_scale)
        
        # Precompute Spatial Kernel Weights
        self.register_buffer('kernel_weights', self._precompute_kernel())
        
        # Precompute kernel offset indices for vectorization
        self._precompute_offsets()

    def _precompute_kernel(self):
        r = torch.arange(-self.radius, self.radius + 1, dtype=torch.float32)
        dy, dx = torch.meshgrid(r, r, indexing='ij')
        
        norm_dy = dy / self.radius
        norm_dx = dx / self.radius
        
        phase_y = norm_dy.unsqueeze(-1) @ self.Y # type: ignore
        phase_x = norm_dx.unsqueeze(-1) @ self.X # type: ignore
        
        return torch.exp(1j * (phase_x + phase_y))
    
    def _precompute_offsets(self):
        """Precompute all kernel offset positions for vectorized gathering."""
        K = self.kernel_size
        offsets_y = []
        offsets_x = []
        
        for dy_idx in range(K):
            for dx_idx in range(K):
                offset_y = dy_idx - self.radius
                offset_x = dx_idx - self.radius
                offsets_y.append(offset_y)
                offsets_x.append(offset_x)
        
        self.register_buffer('offsets_y', torch.tensor(offsets_y, dtype=torch.long))
        self.register_buffer('offsets_x', torch.tensor(offsets_x, dtype=torch.long))
        
        # Flatten kernel weights for vectorized multiplication
        self.register_buffer('kernel_weights_flat', self.kernel_weights.reshape(-1, self.encoding_dim))

    @torch.no_grad()
    def forward(self, t, y, x, query_y, query_x, query_t):
        """
        Args:
            t, y, x: Raw event stream (N,) - used to build the map
            query_y, query_x: Spatial locations of queries (M,)
            query_t: Timestamp of the queries (M,) - used for re-centering
        """
        device = t.device
        
        # ------------------------------------------------------------------
        # PHASE 1: Dense Accumulation (Absolute Time Encoding)
        # ------------------------------------------------------------------
        
        # 1. Normalize Time 
        t_norm = t / self.temporal_length 
        
        # 2. Compute Temporal Embeddings: exp(i * t * T)
        # Shape: (N, D)
        temp_emb = torch.exp(1j * (t_norm.unsqueeze(1) @ self.T))
        
        # 3. Scatter-Add to Grid
        grid_flat = torch.zeros(self.height * self.width, self.encoding_dim, 
                                dtype=torch.cfloat, device=device)
        count_flat = torch.zeros(self.height * self.width, 1, 
                                 dtype=torch.float, device=device)
        
        flat_indices = y.long() * self.width + x.long()
        
        grid_flat.index_add_(0, flat_indices, temp_emb)
        
        ones = torch.ones(t.shape[0], 1, device=device)
        count_flat.index_add_(0, flat_indices, ones)
        
        grid = grid_flat.view(self.height, self.width, self.encoding_dim)
        counts = count_flat.view(self.height, self.width, 1)

        # ------------------------------------------------------------------
        # PHASE 2: Sparse Convolution (Vectorized Gather with Batching)
        # ------------------------------------------------------------------
        
        # Pad grid
        padded_grid = F.pad(grid.permute(2, 0, 1), 
                            (self.radius, self.radius, self.radius, self.radius)).permute(1, 2, 0)
        padded_counts = F.pad(counts.permute(2, 0, 1), 
                              (self.radius, self.radius, self.radius, self.radius)).permute(1, 2, 0)
        
        # Adjust query coords for padding
        q_y = query_y.long() + self.radius
        q_x = query_x.long() + self.radius
        
        num_queries = query_y.shape[0]
        
        # OPTIMIZATION: Process queries in batches to avoid OOM
        # With 600K events, processing all at once requires ~18GB GPU memory
        # Batch size of 5000 queries keeps memory usage under ~150MB per batch
        batch_size = 10000
        num_batches = (num_queries + batch_size - 1) // batch_size
        
        out_emb_list = []
        out_cnt_list = []
        
        for batch_idx in range(num_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, num_queries)
            
            q_y_batch = q_y[start_idx:end_idx]
            q_x_batch = q_x[start_idx:end_idx]
            batch_num_queries = end_idx - start_idx
            
            # VECTORIZED GATHER: Create indices for all kernel positions
            all_y_indices = q_y_batch.unsqueeze(1) + self.offsets_y.unsqueeze(0)  # (batch, K^2)
            all_x_indices = q_x_batch.unsqueeze(1) + self.offsets_x.unsqueeze(0)  # (batch, K^2)
            
            # Gather features and counts for all kernel positions at once
            gathered_feat = padded_grid[all_y_indices, all_x_indices]  # (batch, K^2, D)
            gathered_cnt = padded_counts[all_y_indices, all_x_indices]  # (batch, K^2, 1)
            
            # Apply kernel weights (broadcast multiplication)
            weighted_feat = gathered_feat * self.kernel_weights_flat.unsqueeze(0)
            
            # Sum across kernel positions
            batch_out_emb = weighted_feat.sum(dim=1)  # (batch, D)
            batch_out_cnt = gathered_cnt.sum(dim=1)   # (batch, 1)
            
            out_emb_list.append(batch_out_emb)
            out_cnt_list.append(batch_out_cnt)
        
        # Concatenate all batches
        out_emb = torch.cat(out_emb_list, dim=0)  # (M, D)
        out_cnt = torch.cat(out_cnt_list, dim=0)   # (M, 1)

        # ------------------------------------------------------------------
        # PHASE 3: Temporal Re-centering & Normalization
        # ------------------------------------------------------------------
        
        # 1. Compute re-centering factor for the queries
        qt_norm = query_t / self.temporal_length
        recenter_factor = torch.exp(-1j * (qt_norm.unsqueeze(1) @ self.T))
        
        # 2. Apply re-centering
        out_emb = out_emb * recenter_factor
        
        # 3. Normalize by count
        return out_emb / out_cnt.clamp(min=1)



# --- Verification Script ---
if __name__ == "__main__":
    import time
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    # Test parameters
    height, width = 480, 640
    encoding_dim = 64
    temporal_length = 200.0
    
    # Create both models
    print("\nInitializing models...")
    from SparseVKMEncoder import VecKMSparse
    model_original = VecKMSparse(
        height=height, width=width, encoding_dim=encoding_dim,
        temporal_length=temporal_length, kernel_size=17
    ).to(device)
    
    model_optimized = VecKMSparseOptimized(
        height=height, width=width, encoding_dim=encoding_dim,
        temporal_length=temporal_length, kernel_size=17
    ).to(device)
    
    # Fake Data (realistic size for one interval)
    N = 629_000  # events per interval
    M = 6_290    # vectors per interval (1% sampling)
    
    print(f"\nTest data:")
    print(f"  Events: {N:,}")
    print(f"  Query vectors: {M:,}")
    
    t = torch.sort(torch.rand(N, device=device))[0] * 200.0
    y = torch.randint(0, height, (N,), device=device)
    x = torch.randint(0, width, (N,), device=device)
    
    # Sample query indices
    query_idx = torch.randperm(N, device=device)[:M]
    qy = y[query_idx]
    qx = x[query_idx]
    qt = t[query_idx]
    
    # Warmup
    print("\nWarming up...")
    for _ in range(3):
        _ = model_original(t, y, x, qy, qx, qt)
        _ = model_optimized(t, y, x, qy, qx, qt)
    
    if device == 'cuda':
        torch.cuda.synchronize()
    
    # Benchmark original
    print("\nBenchmarking original VecKMSparse...")
    start = time.time()
    for _ in range(10):
        res_original = model_original(t, y, x, qy, qx, qt)
    if device == 'cuda':
        torch.cuda.synchronize()
    time_original = (time.time() - start) / 10
    
    # Benchmark optimized
    print("Benchmarking optimized VecKMSparseOptimized...")
    start = time.time()
    for _ in range(10):
        res_optimized = model_optimized(t, y, x, qy, qx, qt)
    if device == 'cuda':
        torch.cuda.synchronize()
    time_optimized = (time.time() - start) / 10
    
    # Verify outputs are similar
    diff = torch.abs(res_original - res_optimized).max().item()
    
    print("\n" + "="*70)
    print("BENCHMARK RESULTS")
    print("="*70)
    print(f"Original:   {time_original*1000:.2f} ms/interval")
    print(f"Optimized:  {time_optimized*1000:.2f} ms/interval")
    print(f"Speedup:    {time_original/time_optimized:.2f}x")
    print(f"Max diff:   {diff:.2e} (should be near zero)")
    print("\n" + "="*70)
    print(f"Per sequence ({28} intervals):")
    print(f"  Original:  {time_original * 28:.2f}s")
    print(f"  Optimized: {time_optimized * 28:.2f}s")
    print(f"  Saved:     {(time_original - time_optimized) * 28:.2f}s per sequence")
    print("="*70)
