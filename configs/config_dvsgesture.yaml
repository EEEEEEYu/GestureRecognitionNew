TRAINING:
  deterministic: False
  use_compile: False
  inference_mode: False  # If this one is True, use inference
  seed: 42
  max_epochs: 100 # Increased from 50
  label_smoothing: 0.1 # Soft targets to prevent overconfidence

DISTRIBUTED:
  accelerator: gpu  # Changed from cpu - Mamba2 requires CUDA
  devices: 2
  num_nodes: 1
  strategy: auto

DATA:
  dataset:
    file_name: dvsgesture.dataset_precomputed  # Module path relative to data/
    class_name: DVSGesturePrecomputed
    dataset_init_args:
      # DVSGesture-specific parameters
      precomputed_dir: /fs/nexus-projects/DVS_Actions/DVSGestureData/DVSGesture_precomputed_data
      height: 128
      width: 128
      num_classes: 11  # DVSGesture has 11 classes
      # Second-stage downsampling (training-time augmentation)
      train_ratio_of_vectors: 1.0  # Use 50% of the 30% precomputed vectors = 15% total (Changed from 0.8)
      val_ratio_of_vectors: 1.0    # Use 100% of precomputed vectors during validation
      use_flip_augmentation: False # Disabled as per request
      # Robustness Augmentations
      aug_jitter_std: 0.5       # Coordinate Jitter (pixels/time). Moderate strength.
      aug_drop_rate: 0.1        # Event Drop Rate (10%). Moderate strength.
      aug_time_scale_min: 0.8   # Temporal Scaling Min (20% faster).
      aug_time_scale_max: 1.2   # Temporal Scaling Max (20% slower).

  dataloader:
    batch_size: 8  # Reduced for memory efficiency with Mamba2
    test_batch_size: 8  # Reduced for validation
    num_workers: 8  # Reduced to avoid worker overhead
    persistent_workers: True
    pin_memory: True
    multiprocessing_context: fork
    drop_last: False
    shuffle_train: True
    shuffle_val: False
    shuffle_test: False

MODEL:
  file_name: new_ssm
  class_name: NestedEventMamba
  model_init_args:
    # 3D SSM Architecture parameters
    encoding_dim: 256 
    hidden_dim: 128
    num_classes: ${DATA.dataset.dataset_init_args.num_classes}
    intra_window_blocks: 2
    inter_window_blocks: 2
    intra_window_d_state: 32
    inter_window_d_state: 32
    intra_window_expand: 2
    inter_window_expand: 2  # Must be integer for Mamba2
    dropout: 0.2
    drop_path: 0.2

OPTIMIZER:
  name: AdamW
  arguments:
    lr: 1e-3
    weight_decay: 0.05  # Increased L2 Regularization (now excludes bias/norm)
  gradient_accumulation:
    enabled: False
    scheduling: {0: 4}
  gradient_clip:
    enabled: False
    gradient_clip_val: 1.0
    gradient_clip_algorithm: norm # norm or value
  stochastic_weight_averaging:
    enabled: True
    swa_lrs: 1e-3
    swa_epoch_start: 0.8
    annealing_epochs: 20
    annealing_strategy: cos

SCHEDULER:
  learning_rate:      # For learning rate scheduler, check document: https://docs.pytorch.org/docs/2.8/optim.html#how-to-adjust-learning-rate
    enabled: True
    name: CosineAnnealingLR
    arguments:
      T_max: ${TRAINING.max_epochs}  # Matched to max_epochs
      eta_min: 1e-6
  early_stopping:
    enabled: False
    monitor: val_loss_epoch
    mode: min
    patience: 5
    min_delta: 1e-5
  
LOGGER:
  log_dir_root: lightning_logs
  experiment_name: hilbert_ssm_dvsgesture

CHECKPOINT:
  enabled: True
  every_n_epochs: 1
  monitor: val_top1_acc_epoch
  mode: max
  filename: "best-{epoch:03d}-{val_top1_acc_epoch:.5f}"
  save_top_k: 1
  save_last: True

PRECOMPUTING:
  dataset_dir: /fs/nexus-projects/DVS_Actions/DVSGestureData
  output_dir: /fs/nexus-projects/DVS_Actions/DVSGestureData/DVSGesture_precomputed_data
  accumulation_interval_ms: 200.0  # Window size for splitting event stream
  ratio_of_vectors: 0.1  # Retention ratio for sampling (what % of denoised events to keep as queries)
  encoding_dim: ${MODEL.model_init_args.encoding_dim}
  temporal_length: 200.0  # Should match accumulation_interval_ms
  kernel_size: 17
  T_scale: 25.0
  S_scale: 25.0
  height: 128
  width: 128
  num_workers: 8  # Number of workers for parallel preprocessing
  checkpoint_every_n_samples: 50  # Save checkpoint every N samples during preprocessing
  
  # Rotation augmentation (precomputed)
  # Rotations are applied to raw events BEFORE VKM encoding to preserve geometric structure
  rotation_augmentation:
    enabled: False
    angles: [0, 90, 180, 270]  # Cardinal rotations in degrees
    mode: separate  # Store each rotation as a separate sample (simpler dataloader)
    augment_validation: False  # Only augment training data, keep validation at 0Â° only
  
  
  # Denoising parameters (applied BEFORE sampling)
  # Use benchmark_denoising.py to find optimal parameters for your dataset
  denoising:
    enabled: True  # Set to False to disable denoising
    grid_size: 2  # Spatial grid size for noise filtering (pixels)
    threshold: 6  # Minimum events per grid cell to survive filtering
  
  # Sampling strategy for query selection
  # Determines how to select which events become query vectors for VecKM encoding
  # Applied AFTER denoising
  sampling:
    method: adaptive_striding  # Options: 'random', 'grid_decimation', 'adaptive_striding' (recommended)
    
    # Kernel-Aware Adaptive Striding
    # Selects queries to cover the spatial domain with kernel_size and specified overlap.
    adaptive_striding:
      kernel_size: ${PRECOMPUTING.kernel_size}  # Match encoder kernel size
      overlap_factor: 0.8  # 0.0=Tiling, 0.5=Half-Overlap. Controls density.
    
    # Grid decimation parameters (used when method=grid_decimation)
    # This method uses stratified sampling with retention_ratio from ratio_of_vectors above
    grid_decimation:
      grid_size: 2  # Spatial grid size for stratified sampling (smaller = finer sampling)

BENCHMARKING:
  # Benchmark settings for automated parameter search
  # These control both denoising and sampling benchmarks
  
  num_samples: 100  # Number of dataset samples to use for benchmarking
  
  # Denoising benchmark parameter ranges
  denoising:
    grid_sizes: [2, 3, 4, 5, 6, 8, 10]
    thresholds: [1, 2, 3, 4, 5, 6]
  
  # Sampling benchmark parameter ranges
  sampling:
    grid_sizes: [2, 3, 4, 6, 8, 10, 12]
    retention_ratios: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.08, 0.1]
  
  # Intermediate denoised data storage (for decoupled benchmarking)
  # After denoising benchmark, run preprocess_denoise_only.py to save denoised events
  # Then sampling benchmark will load from this directory
  denoised_cache_dir: /fs/nexus-projects/DVS_Actions/DVSGestureData/DVSGesture_precomputed_data/DVSGesture_denoised_cache



